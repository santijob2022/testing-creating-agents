{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d515aa88",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a6c2a6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import logging\n",
    "\n",
    "# Suppress user warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Suppress Gradio & uvicorn logs\n",
    "logging.getLogger(\"gradio\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"uvicorn\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"uvicorn.error\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"uvicorn.access\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a07e7793-b8f5-44f4-aded-5562f633271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import anthropic\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9d1571",
   "metadata": {},
   "source": [
    "### Loading API's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4e29645a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key exists and begins sk-ant-\n",
      "Deepseek API Key exists and begins sk-ant-\n",
      "Google API Key not set\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set\")\n",
    "\n",
    "if anthropic_api_key:\n",
    "    print(f\"Deepseek API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Deepseek API Key not set\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1547c2",
   "metadata": {},
   "source": [
    "### Making the connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7eb7ca20",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI()\n",
    "\n",
    "claude = anthropic.Anthropic()\n",
    "\n",
    "deepseek = OpenAI(\n",
    "    api_key=deepseek_api_key, \n",
    "    base_url=\"https://api.deepseek.com\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90577f8",
   "metadata": {},
   "source": [
    "### Creating Welcome Image with dall-e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "aca0e0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "def welcome_image():\n",
    "    \"\"\"Function to generate the welcome image in the chatbot making reference to the Booking experience.\"\"\"\n",
    "\n",
    "    if os.path.exists(\"welcome_image_booking.png\"):\n",
    "        image = Image.open(\"welcome_image_booking.png\")\n",
    "    else:\n",
    "        image_response = openai.images.generate(\n",
    "                model=\"dall-e-3\",\n",
    "                prompt=f\"\"\"Create a photorealistic welcome image with the text \n",
    "                \"Welcome!\"\n",
    "                in a clear, elegant, and formal font.             \n",
    "                In the center, there's a modern glass hut. \n",
    "                In front of the hut, a couple is peacefully sitting on the ground, gently illuminated by sun rays \n",
    "                filtering through the canopy. Around the border of the image, the subtle silhouettes of curious \n",
    "                jungle animals are partially visible, watching the couple with interest. \n",
    "                The overall mood is serene and inviting.\n",
    "                The background features a lush jungle with vivid greenery.\n",
    "                \"\"\",\n",
    "                size=\"1024x1024\",\n",
    "                quality=\"standard\",\n",
    "                n=1,\n",
    "                response_format=\"b64_json\",\n",
    "                style=\"vivid\"       \n",
    "            )\n",
    "        image_base64 = image_response.data[0].b64_json\n",
    "        image_data = base64.b64decode(image_base64)\n",
    "        image = Image.open(BytesIO(image_data))\n",
    "\n",
    "        # Save the image\n",
    "        image.save(\"welcome_image_booking.png\", format=\"PNG\")\n",
    "        print(\"Image generated and saved.\")\n",
    "    # Display the image\n",
    "    # display(image)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8132b3e",
   "metadata": {},
   "source": [
    "### Defining the chatbot system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "16eca57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify this according to system updates\n",
    "system_message = \"You are a helpful assistant for making booking reservations. \"\n",
    "system_message += \"Give short, courteous answers, no more than 1 sentence.\"\n",
    "system_message += \"Always be accurate. If you don't know the answer, say so.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6663e4b5",
   "metadata": {},
   "source": [
    "### Defining the selected model in streaming mode\n",
    "\n",
    "This depends on the model chosen by the user and will also be useful to pick a model to answer certain type of questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ccf2b7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(prompt, history, model):\n",
    "    if history is None:\n",
    "        history = []\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "    # print(\"History is:\")\n",
    "    # print(history)\n",
    "    # print(\"And messages is:\")\n",
    "    # print(messages)\n",
    "\n",
    "    assistant_msg = \"\"\n",
    "\n",
    "    if model == \"GPT\":\n",
    "        stream = openai.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",  # or use another GPT variant\n",
    "            messages=messages,\n",
    "            stream=True,\n",
    "        )\n",
    "        for chunk in stream:\n",
    "            delta = chunk.choices[0].delta.content or \"\"\n",
    "            assistant_msg += delta\n",
    "            yield history + [{\"role\": \"user\", \"content\": prompt}, {\"role\": \"assistant\", \"content\": assistant_msg}]\n",
    "\n",
    "    elif model == \"Claude\":\n",
    "        # Try to recover original user prompt from last history item\n",
    "        if not prompt.strip() and history and history[-1][\"role\"] == \"user\":\n",
    "            prompt = history[-1][\"content\"]\n",
    "\n",
    "        if not prompt.strip():\n",
    "            yield history + [{\"role\": \"assistant\", \"content\": \"(Empty prompt)\"}]\n",
    "            return\n",
    "\n",
    "        system = system_message.strip() if system_message and system_message.strip() else None\n",
    "        result = claude.messages.stream(\n",
    "            model=\"claude-3-haiku-20240307\",\n",
    "            max_tokens=1000,\n",
    "            temperature=0.7,\n",
    "            system=system,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        )\n",
    "\n",
    "        assistant_msg = \"\"\n",
    "        with result as stream:\n",
    "            for text in stream.text_stream:\n",
    "                assistant_msg += text or \"\"\n",
    "                yield history + [{\"role\": \"assistant\", \"content\": assistant_msg}]\n",
    "\n",
    "\n",
    "    elif model == \"Deepseek\":\n",
    "        stream = deepseek.chat.completions.create(\n",
    "            model=\"deepseek-chat\",\n",
    "            messages=messages,\n",
    "            stream=True,\n",
    "        )\n",
    "        for chunk in stream:\n",
    "            delta = chunk.choices[0].delta.content or \"\"\n",
    "            assistant_msg += delta\n",
    "            yield history + [{\"role\": \"user\", \"content\": prompt}, {\"role\": \"assistant\", \"content\": assistant_msg}]\n",
    "\n",
    "    else:\n",
    "        # fallback or unknown model\n",
    "        assistant_msg = \"Unknown model selected.\"\n",
    "        yield history + [{\"role\": \"user\", \"content\": prompt}, {\"role\": \"assistant\", \"content\": assistant_msg}]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48815d95",
   "metadata": {},
   "source": [
    "### Defining Audio Output\n",
    "\n",
    "The audio section will need to install ffmpeg to work on Windows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc6ca9e",
   "metadata": {},
   "source": [
    "### Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "259111c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7886\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7886/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "with gr.Blocks() as ui:\n",
    "    with gr.Row():\n",
    "        chatbot = gr.Chatbot(value=[],height=500, type=\"messages\")\n",
    "        image_output = gr.Image(value=welcome_image(),height=500)\n",
    "    with gr.Row():        \n",
    "        entry = gr.Textbox(label=\"Chat with our AI Assistant:\")\n",
    "    with gr.Row():        \n",
    "        model_selector = gr.Dropdown([\"GPT\", \"Claude\", \"Deepseek\"], label=\"Select model\", value=\"GPT\")\n",
    "    with gr.Row():\n",
    "        clear = gr.Button(\"Clear\")        \n",
    "\n",
    "    def do_entry(message, history, model):\n",
    "        if not message.strip():\n",
    "            return \"\", history, model  # Do nothing if prompt is empty\n",
    "        if history is None:\n",
    "            history = []\n",
    "        history += [{\"role\": \"user\", \"content\": message}]\n",
    "        return \"\", history, model\n",
    "    \n",
    "    entry.submit(fn=do_entry, \n",
    "                 inputs=[entry, chatbot, model_selector], \n",
    "                 outputs=[entry, chatbot,model_selector]).then(\n",
    "                     chat, \n",
    "                     inputs=[entry, chatbot, model_selector], \n",
    "                     outputs=chatbot\n",
    "                     ).then(\n",
    "                         lambda: \"\", None, entry\n",
    "                     )\n",
    "\n",
    "    clear.click(lambda: None, inputs=None, outputs=chatbot, queue=False)\n",
    "\n",
    "# ui.launch(inbrowser=True, server_port=7868,prevent_thread_lock=True)\n",
    "ui.launch(inbrowser=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a3be64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa0d822",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d149e04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238e582e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5168d6a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8b8f27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a922cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51e50c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3fd35f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24abc757",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
